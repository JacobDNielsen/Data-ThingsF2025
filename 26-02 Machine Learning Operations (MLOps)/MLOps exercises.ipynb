{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dc0175-b2ca-4c23-92a5-19f30bbc975b",
   "metadata": {},
   "source": [
    "# MLOps exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b38eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a76de-8b93-465e-86af-0c2a8e9ea02e",
   "metadata": {},
   "source": [
    "## Execise 1\n",
    "\n",
    "In this exercise, do the following:\n",
    "1. Create a function that preprocess new ames data in the same way as the original ames data was preprocessed in step 5 in the `MLOps.ipynb` notebook.\n",
    "2. Create a function that takes as input a new ames dataset and a model. The function should pre-process the new data and evaluate the model on that new data using mean absolute error.\n",
    "3. Test the function from 2. on the \"NewAmesData1.csv\" dataset and the best model from the `MLOps.ipynb` notebook.\n",
    "4. Test the function from 2. on the \"NewAmesData2.csv\" dataset and the best model from the `MLOps.ipynb` notebook. Do you see any drift?\n",
    "5. Do you see a data drift in \"NewAmesData2.csv\"? If so, for which variables?\n",
    "6. Do you see a data drift in \"NewAmesData4.csv\"? If so, for which variables?\n",
    "7. Create a function that retrain a model on the new data as well as the old training data\n",
    "8. Retrain the `model_final` on the new data \"NewAmesData1.csv\" as well as the old training data, using the function from 5. Then test the new model on the old testset.\n",
    "9. Split the \"NewAmesData2.csv\" dataset into a train and test set. Train  the best model from the `MLOps.ipynb` notebook on the training part and test it on the test part. Did you get a better model? Now combine your new training data with the original training data and retrain the model on that. Did that give you a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ac6a31-ec39-4d31-aa94-4c8ef9f0d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(dataset_path):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    return df\n",
    "\n",
    "def transform(df):\n",
    "    df = df[[\"Lot Area\", \"Overall Cond\", \"Year Built\", \"Gr Liv Area\", \"TotRms AbvGrd\", \"Mo Sold\", \"Yr Sold\", \"Bldg Type\", \"Neighborhood\", \"SalePrice\"]]\n",
    "    df = df[df[\"Lot Area\"] <= 75000]\n",
    "\n",
    "    df = df.join(pd.get_dummies(df[\"Bldg Type\"], drop_first=True, dtype = \"int\", prefix=\"BType\"))\n",
    "    df = df.join(pd.get_dummies(df[\"Neighborhood\"], drop_first=True, dtype = \"int\", prefix=\"Nbh\"))\n",
    "    df = df.drop(columns = [\"Bldg Type\", \"Neighborhood\"])\n",
    "    return df\n",
    "\n",
    "def ETL(dataset_path):\n",
    "    df= extract(dataset_path)\n",
    "    df_transformed = transform(df)\n",
    "    return df_transformed\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd27dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>BType_2fmCon</th>\n",
       "      <th>BType_Duplex</th>\n",
       "      <th>...</th>\n",
       "      <th>Nbh_NoRidge</th>\n",
       "      <th>Nbh_NridgHt</th>\n",
       "      <th>Nbh_OldTown</th>\n",
       "      <th>Nbh_SWISU</th>\n",
       "      <th>Nbh_Sawyer</th>\n",
       "      <th>Nbh_SawyerW</th>\n",
       "      <th>Nbh_Somerst</th>\n",
       "      <th>Nbh_StoneBr</th>\n",
       "      <th>Nbh_Timber</th>\n",
       "      <th>Nbh_Veenker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10738</td>\n",
       "      <td>6</td>\n",
       "      <td>1954</td>\n",
       "      <td>1457</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>132661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13835</td>\n",
       "      <td>4</td>\n",
       "      <td>1989</td>\n",
       "      <td>1792</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>372144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9667</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1103</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>150786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10699</td>\n",
       "      <td>6</td>\n",
       "      <td>2000</td>\n",
       "      <td>1671</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>211081</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14033</td>\n",
       "      <td>4</td>\n",
       "      <td>1992</td>\n",
       "      <td>1357</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>142802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lot Area  Overall Cond  Year Built  Gr Liv Area  TotRms AbvGrd  Mo Sold  \\\n",
       "0     10738             6        1954         1457              5        8   \n",
       "1     13835             4        1989         1792              6        3   \n",
       "2      9667             5        1997         1103              6        5   \n",
       "3     10699             6        2000         1671              6        4   \n",
       "4     14033             4        1992         1357              5       10   \n",
       "\n",
       "   Yr Sold  SalePrice  BType_2fmCon  BType_Duplex  ...  Nbh_NoRidge  \\\n",
       "0     2009     132661             0             0  ...            0   \n",
       "1     2006     372144             0             0  ...            0   \n",
       "2     2010     150786             0             0  ...            0   \n",
       "3     2009     211081             0             0  ...            0   \n",
       "4     2009     142802             0             0  ...            0   \n",
       "\n",
       "   Nbh_NridgHt  Nbh_OldTown  Nbh_SWISU  Nbh_Sawyer  Nbh_SawyerW  Nbh_Somerst  \\\n",
       "0            0            0          0           0            0            0   \n",
       "1            1            0          0           0            0            0   \n",
       "2            0            0          0           0            1            0   \n",
       "3            0            0          0           0            0            0   \n",
       "4            0            0          0           0            0            0   \n",
       "\n",
       "   Nbh_StoneBr  Nbh_Timber  Nbh_Veenker  \n",
       "0            0           0            0  \n",
       "1            0           0            0  \n",
       "2            0           0            0  \n",
       "3            0           0            0  \n",
       "4            0           0            0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_path = \"NewAmesData1.csv\"\n",
    "\n",
    "# df = ETL(dataset_path)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a2201",
   "metadata": {},
   "source": [
    "2. Create a function that takes as input a new ames dataset and a model. The function should pre-process the new data and evaluate the model on that new data using mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119b16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_500_ = mlflow.sklearn.load_model(\"mlflow_rf_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed318d14",
   "metadata": {},
   "source": [
    "No loops, that is in mlflow_task!!!! This excersies. Use the trained model from MLOPS., DONT TRAIN IN THE MODEL_EVALUATOR, No preprocessing in model_evaluator, should just send data to ETL. Open model from the MLOPS\n",
    "\n",
    "Use MLFLOW\n",
    "\n",
    "pip freeze > requinrements.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5205d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluator(dataset_path, model_rf_500_):\n",
    "    df = ETL(dataset_path)\n",
    "    X_new = df.drop(columns=[\"SalePrice\"])  # Adjust if the target column differs\n",
    "    y_true = df[\"SalePrice\"]\n",
    "    y_pred = model_rf_500_.predict(X_new)\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "## no train_test_split here, model should already be trained!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb37be7",
   "metadata": {},
   "source": [
    "3. Test the function from 2. on the \"NewAmesData1.csv\" dataset and the best model from the `MLOps.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc163be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19268.3361078475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = model_evaluator(\"NewAmesData1.csv\", model_rf_500_)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906eb562",
   "metadata": {},
   "source": [
    "4. Test the function from 2. on the \"NewAmesData2.csv\" dataset and the best model from the `MLOps.ipynb` notebook. Do you see any drift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ddede74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122715.83893998136"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = model_evaluator(\"NewAmesData2.csv\", model_rf_500_)\n",
    "mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
