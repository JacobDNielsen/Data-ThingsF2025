{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import IPython.display as display\n",
    "import tempfile\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execise 1\n",
    "\n",
    "In this exercise, do the following:\n",
    "1. Load the dataset used in the time series example - Energy consumption data. You can find it in the notebook \"TSA_Example\" in Time Series folder in Moodle.\n",
    "2. Setup a nested MLFlow loop where different modelling experiments can be tracked and the use the dataset in point 1 to experiment and track models. You should do following combinations:\n",
    "    1. At least 3 model types\n",
    "    2. At least 3 different feature combinations\n",
    "    3. At least 3 different options for 3 different hyperparameters\n",
    "    4. At least 3 different time splits for train test\n",
    "3. For each option in the combination, you should calculate & log the following in MLFlow:\n",
    "    1. RMSE\n",
    "    2. MAE\n",
    "    3. Plot of actual vs predicted for 1 month data\n",
    "    4. Plot of actual vs predicted for 1 week of data\n",
    "    5. All of the combination info in point 2, such as which model, what feature combindation, what hyperparameter, what train test split has been used\n",
    "4. Turn on MLFlow UI and track your experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the dataset used in the time series example - Energy consumption data. You can find it in the notebook \"TSA_Example\" in Time Series folder in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\Jacob\\.cache\\kagglehub\\datasets\\robikscube\\hourly-energy-consumption\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"robikscube/hourly-energy-consumption\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AEP_hourly.csv', 'COMED_hourly.csv', 'DAYTON_hourly.csv', 'DEOK_hourly.csv', 'DOM_hourly.csv', 'DUQ_hourly.csv', 'EKPC_hourly.csv', 'est_hourly.paruqet', 'FE_hourly.csv', 'NI_hourly.csv', 'PJME_hourly.csv', 'PJMW_hourly.csv', 'pjm_hourly_est.csv', 'PJM_Load_hourly.csv']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/Jacob/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3\"\n",
    "\n",
    "files = os.listdir(dataset_path)\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Jacob/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3/PJME_hourly.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PJME_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-12-31 01:00:00</td>\n",
       "      <td>26498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-12-31 02:00:00</td>\n",
       "      <td>25147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-12-31 03:00:00</td>\n",
       "      <td>24574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-12-31 04:00:00</td>\n",
       "      <td>24393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-12-31 05:00:00</td>\n",
       "      <td>24860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145361</th>\n",
       "      <td>2018-01-01 20:00:00</td>\n",
       "      <td>44284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145362</th>\n",
       "      <td>2018-01-01 21:00:00</td>\n",
       "      <td>43751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145363</th>\n",
       "      <td>2018-01-01 22:00:00</td>\n",
       "      <td>42402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145364</th>\n",
       "      <td>2018-01-01 23:00:00</td>\n",
       "      <td>40164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145365</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>38608.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145366 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime  PJME_MW\n",
       "0       2002-12-31 01:00:00  26498.0\n",
       "1       2002-12-31 02:00:00  25147.0\n",
       "2       2002-12-31 03:00:00  24574.0\n",
       "3       2002-12-31 04:00:00  24393.0\n",
       "4       2002-12-31 05:00:00  24860.0\n",
       "...                     ...      ...\n",
       "145361  2018-01-01 20:00:00  44284.0\n",
       "145362  2018-01-01 21:00:00  43751.0\n",
       "145363  2018-01-01 22:00:00  42402.0\n",
       "145364  2018-01-01 23:00:00  40164.0\n",
       "145365  2018-01-02 00:00:00  38608.0\n",
       "\n",
       "[145366 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145366 entries, 0 to 145365\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   Datetime  145366 non-null  object \n",
      " 1   PJME_MW   145366 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 01:00:00</th>\n",
       "      <td>30393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>29265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>28357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>27899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 05:00:00</th>\n",
       "      <td>28057.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW\n",
       "Datetime                    \n",
       "2002-01-01 01:00:00  30393.0\n",
       "2002-01-01 02:00:00  29265.0\n",
       "2002-01-01 03:00:00  28357.0\n",
       "2002-01-01 04:00:00  27899.0\n",
       "2002-01-01 05:00:00  28057.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-11-02 02:00:00', '2014-11-02 02:00:00',\n",
       "               '2015-11-01 02:00:00', '2015-11-01 02:00:00',\n",
       "               '2016-11-06 02:00:00', '2016-11-06 02:00:00',\n",
       "               '2017-11-05 02:00:00', '2017-11-05 02:00:00'],\n",
       "              dtype='datetime64[ns]', name='Datetime', freq=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate indices\n",
    "duplicate_indices = df.index[df.index.duplicated(keep=False)]\n",
    "duplicate_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-11-02 01:00:00</th>\n",
       "      <td>23538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 02:00:00</th>\n",
       "      <td>23755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 02:00:00</th>\n",
       "      <td>22935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 03:00:00</th>\n",
       "      <td>22789.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW\n",
       "Datetime                    \n",
       "2014-11-02 01:00:00  23538.0\n",
       "2014-11-02 02:00:00  23755.0\n",
       "2014-11-02 02:00:00  22935.0\n",
       "2014-11-02 03:00:00  22789.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['2014-11-02 01:00:00':'2014-11-02 03:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2002-04-07 03:00:00', '2002-10-27 02:00:00',\n",
       "               '2003-04-06 03:00:00', '2003-10-26 02:00:00',\n",
       "               '2004-04-04 03:00:00', '2004-10-31 02:00:00',\n",
       "               '2005-04-03 03:00:00', '2005-10-30 02:00:00',\n",
       "               '2006-04-02 03:00:00', '2006-10-29 02:00:00',\n",
       "               '2007-03-11 03:00:00', '2007-11-04 02:00:00',\n",
       "               '2008-03-09 03:00:00', '2008-11-02 02:00:00',\n",
       "               '2009-03-08 03:00:00', '2009-11-01 02:00:00',\n",
       "               '2010-03-14 03:00:00', '2010-11-07 02:00:00',\n",
       "               '2010-12-10 00:00:00', '2011-03-13 03:00:00',\n",
       "               '2011-11-06 02:00:00', '2012-03-11 03:00:00',\n",
       "               '2012-11-04 02:00:00', '2013-03-10 03:00:00',\n",
       "               '2013-11-03 02:00:00', '2014-03-09 03:00:00',\n",
       "               '2015-03-08 03:00:00', '2016-03-13 03:00:00',\n",
       "               '2017-03-12 03:00:00', '2018-03-11 03:00:00'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_of_dates = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
    "missing_timestamps = range_of_dates.difference(df.index)\n",
    "missing_timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-07 02:00:00</th>\n",
       "      <td>24738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-07 04:00:00</th>\n",
       "      <td>24487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-07 05:00:00</th>\n",
       "      <td>24617.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW\n",
       "Datetime                    \n",
       "2002-04-07 02:00:00  24738.0\n",
       "2002-04-07 04:00:00  24487.0\n",
       "2002-04-07 05:00:00  24617.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['2002-04-07 02:00:00':'2002-04-07 05:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows with duplicated indices\n",
    "df = df[~df.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding missing dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reindex(range_of_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_22204\\567689999.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 145392 entries, 2002-01-01 01:00:00 to 2018-08-03 00:00:00\n",
      "Freq: h\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   PJME_MW  145392 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = df.index.hour\n",
    "df[\"day\"] = df.index.day\n",
    "df[\"month\"] = df.index.month\n",
    "df[\"weekday\"] = df.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 01:00:00</th>\n",
       "      <td>30393.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>29265.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>28357.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>27899.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 05:00:00</th>\n",
       "      <td>28057.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW  hour  day  month  weekday\n",
       "2002-01-01 01:00:00  30393.0     1    1      1        1\n",
       "2002-01-01 02:00:00  29265.0     2    1      1        1\n",
       "2002-01-01 03:00:00  28357.0     3    1      1        1\n",
       "2002-01-01 04:00:00  27899.0     4    1      1        1\n",
       "2002-01-01 05:00:00  28057.0     5    1      1        1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 145392 entries, 2002-01-01 01:00:00 to 2018-08-03 00:00:00\n",
      "Freq: h\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   PJME_MW  145392 non-null  float64\n",
      " 1   hour     145392 non-null  int32  \n",
      " 2   day      145392 non-null  int32  \n",
      " 3   month    145392 non-null  int32  \n",
      " 4   weekday  145392 non-null  int32  \n",
      "dtypes: float64(1), int32(4)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "\n",
    "    df = df.copy()\n",
    "    # Lag features\n",
    "    df['lag_1d'] = df['PJME_MW'].shift(1*24)   # 1 day lag\n",
    "    df['lag_1w'] = df['PJME_MW'].shift(7*24)   # 1 week lag\n",
    "    df['lag_1m'] = df['PJME_MW'].shift(30*24)  # 1 month lag\n",
    "\n",
    "    # Rolling statistics features\n",
    "    df['rolling_mean_1d'] = df['PJME_MW'].rolling(window=1*24).mean()  # Last 1 day rolling mean\n",
    "    df['rolling_mean_7d'] = df['PJME_MW'].rolling(window=7*24).mean()  # Last 7 days rolling mean\n",
    "    df['rolling_mean_30d'] = df['PJME_MW'].rolling(window=30*24).mean()  # Last 30 days rolling mean\n",
    "    df['rolling_mean_90d'] = df['PJME_MW'].rolling(window=90*24).mean()  # Last 90 days rolling mean\n",
    "    df['rolling_mean_same_month_last_year'] = df['PJME_MW'].shift(365*24).rolling(window=30*24).mean()  # Same month previous year rolling mean\n",
    "    df['rolling_mean_same_week_last_year'] = df['PJME_MW'].shift(365*24).rolling(window=7*24).mean()  # Same week previous year rolling mean\n",
    "    df['rolling_mean_same_day_last_year'] = df['PJME_MW'].shift(365*24).rolling(window=1*24).mean()  # Same day previous year rolling mean\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>lag_1d</th>\n",
       "      <th>lag_1w</th>\n",
       "      <th>lag_1m</th>\n",
       "      <th>rolling_mean_1d</th>\n",
       "      <th>rolling_mean_7d</th>\n",
       "      <th>rolling_mean_30d</th>\n",
       "      <th>rolling_mean_90d</th>\n",
       "      <th>rolling_mean_same_month_last_year</th>\n",
       "      <th>rolling_mean_same_week_last_year</th>\n",
       "      <th>rolling_mean_same_day_last_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-02 20:00:00</th>\n",
       "      <td>44057.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>46912.0</td>\n",
       "      <td>46337.0</td>\n",
       "      <td>49244.0</td>\n",
       "      <td>39902.916667</td>\n",
       "      <td>35900.238095</td>\n",
       "      <td>36195.288889</td>\n",
       "      <td>32695.102315</td>\n",
       "      <td>36598.879167</td>\n",
       "      <td>33901.708333</td>\n",
       "      <td>37874.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 21:00:00</th>\n",
       "      <td>43256.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>45985.0</td>\n",
       "      <td>44542.0</td>\n",
       "      <td>47292.0</td>\n",
       "      <td>39789.208333</td>\n",
       "      <td>35892.583333</td>\n",
       "      <td>36189.683333</td>\n",
       "      <td>32697.885648</td>\n",
       "      <td>36594.200000</td>\n",
       "      <td>33910.625000</td>\n",
       "      <td>37660.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 22:00:00</th>\n",
       "      <td>41552.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>44094.0</td>\n",
       "      <td>42638.0</td>\n",
       "      <td>45506.0</td>\n",
       "      <td>39683.291667</td>\n",
       "      <td>35886.119048</td>\n",
       "      <td>36184.191667</td>\n",
       "      <td>32700.633333</td>\n",
       "      <td>36589.688889</td>\n",
       "      <td>33918.482143</td>\n",
       "      <td>37472.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 23:00:00</th>\n",
       "      <td>38500.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>40666.0</td>\n",
       "      <td>39276.0</td>\n",
       "      <td>42437.0</td>\n",
       "      <td>39593.041667</td>\n",
       "      <td>35881.500000</td>\n",
       "      <td>36178.723611</td>\n",
       "      <td>32703.043056</td>\n",
       "      <td>36585.406944</td>\n",
       "      <td>33926.244048</td>\n",
       "      <td>37309.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 00:00:00</th>\n",
       "      <td>35486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>37158.0</td>\n",
       "      <td>35742.0</td>\n",
       "      <td>39340.0</td>\n",
       "      <td>39523.375000</td>\n",
       "      <td>35879.976190</td>\n",
       "      <td>36173.370833</td>\n",
       "      <td>32705.528241</td>\n",
       "      <td>36581.276389</td>\n",
       "      <td>33933.797619</td>\n",
       "      <td>37164.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW  hour  day  month  weekday   lag_1d   lag_1w  \\\n",
       "2018-08-02 20:00:00  44057.0    20    2      8        3  46912.0  46337.0   \n",
       "2018-08-02 21:00:00  43256.0    21    2      8        3  45985.0  44542.0   \n",
       "2018-08-02 22:00:00  41552.0    22    2      8        3  44094.0  42638.0   \n",
       "2018-08-02 23:00:00  38500.0    23    2      8        3  40666.0  39276.0   \n",
       "2018-08-03 00:00:00  35486.0     0    3      8        4  37158.0  35742.0   \n",
       "\n",
       "                      lag_1m  rolling_mean_1d  rolling_mean_7d  \\\n",
       "2018-08-02 20:00:00  49244.0     39902.916667     35900.238095   \n",
       "2018-08-02 21:00:00  47292.0     39789.208333     35892.583333   \n",
       "2018-08-02 22:00:00  45506.0     39683.291667     35886.119048   \n",
       "2018-08-02 23:00:00  42437.0     39593.041667     35881.500000   \n",
       "2018-08-03 00:00:00  39340.0     39523.375000     35879.976190   \n",
       "\n",
       "                     rolling_mean_30d  rolling_mean_90d  \\\n",
       "2018-08-02 20:00:00      36195.288889      32695.102315   \n",
       "2018-08-02 21:00:00      36189.683333      32697.885648   \n",
       "2018-08-02 22:00:00      36184.191667      32700.633333   \n",
       "2018-08-02 23:00:00      36178.723611      32703.043056   \n",
       "2018-08-03 00:00:00      36173.370833      32705.528241   \n",
       "\n",
       "                     rolling_mean_same_month_last_year  \\\n",
       "2018-08-02 20:00:00                       36598.879167   \n",
       "2018-08-02 21:00:00                       36594.200000   \n",
       "2018-08-02 22:00:00                       36589.688889   \n",
       "2018-08-02 23:00:00                       36585.406944   \n",
       "2018-08-03 00:00:00                       36581.276389   \n",
       "\n",
       "                     rolling_mean_same_week_last_year  \\\n",
       "2018-08-02 20:00:00                      33901.708333   \n",
       "2018-08-02 21:00:00                      33910.625000   \n",
       "2018-08-02 22:00:00                      33918.482143   \n",
       "2018-08-02 23:00:00                      33926.244048   \n",
       "2018-08-03 00:00:00                      33933.797619   \n",
       "\n",
       "                     rolling_mean_same_day_last_year  \n",
       "2018-08-02 20:00:00                     37874.750000  \n",
       "2018-08-02 21:00:00                     37660.416667  \n",
       "2018-08-02 22:00:00                     37472.750000  \n",
       "2018-08-02 23:00:00                     37309.500000  \n",
       "2018-08-03 00:00:00                     37164.500000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the first combination\n",
    "# X = df.drop(columns=[\"PJME_MW\"])\n",
    "# y = df['PJME_MW']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Define different feature combinations\n",
    "# # Define 3 feature combinations based on your dataset\n",
    "# feature_combinations = [\n",
    "#     [\"hour\", \"day\", \"month\"],  # Combination 1: Time-based features (hour, day, month)\n",
    "#     [\"lag_1d\", \"lag_1w\", \"lag_1m\"],  # Combination 2: Lag features (1-day, 1-week, 1-month lags)\n",
    "#     [\"rolling_mean_1d\", \"rolling_mean_7d\", \"rolling_mean_30d\"],  # Combination 3: Rolling averages (short-term and long-term)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setup a nested MLFlow loop where different modelling experiments can be tracked and the use the dataset in point 1 to experiment and track models. You should do following combinations:\n",
    "    1. At least 3 model types\n",
    "    2. At least 3 different feature combinations\n",
    "    3. At least 3 different options for 3 different hyperparameters\n",
    "    4. At least 3 different time splits for train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combinations = [\n",
    "    [\"hour\", \"day\", \"month\"],  # Combination 1: Time-based features (hour, day, month)\n",
    "    [\"lag_1d\", \"lag_1w\", \"lag_1m\"],  # Combination 2: Lag features (1-day, 1-week, 1-month lags)\n",
    "    [\"rolling_mean_1d\", \"rolling_mean_7d\", \"rolling_mean_30d\"],  # Combination 3: Rolling averages (short-term and long-term)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 145392 entries, 2002-01-01 01:00:00 to 2018-08-03 00:00:00\n",
      "Freq: h\n",
      "Data columns (total 15 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   PJME_MW                            145392 non-null  float64\n",
      " 1   hour                               145392 non-null  int32  \n",
      " 2   day                                145392 non-null  int32  \n",
      " 3   month                              145392 non-null  int32  \n",
      " 4   weekday                            145392 non-null  int32  \n",
      " 5   lag_1d                             145368 non-null  float64\n",
      " 6   lag_1w                             145224 non-null  float64\n",
      " 7   lag_1m                             144672 non-null  float64\n",
      " 8   rolling_mean_1d                    145369 non-null  float64\n",
      " 9   rolling_mean_7d                    145225 non-null  float64\n",
      " 10  rolling_mean_30d                   144673 non-null  float64\n",
      " 11  rolling_mean_90d                   143233 non-null  float64\n",
      " 12  rolling_mean_same_month_last_year  135913 non-null  float64\n",
      " 13  rolling_mean_same_week_last_year   136465 non-null  float64\n",
      " 14  rolling_mean_same_day_last_year    136609 non-null  float64\n",
      "dtypes: float64(11), int32(4)\n",
      "memory usage: 19.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor,\n",
    "    \"XGBoost\": XGBRegressor,\n",
    "    \"LinearRegression\": LinearRegression\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    },\n",
    "    \"LinearRegression\": {'copy_X': [True,False], \n",
    "               'fit_intercept': [True,False], \n",
    "               'n_jobs': [1,5,10,15,None], \n",
    "               'positive': [True,False]\n",
    "               }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_splits = [\n",
    "    (0.8, 0.2),  # 80% train, 20% test\n",
    "    (0.7, 0.3),\n",
    "    (0.9, 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('model_tracking_experiment')\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/27 16:45:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:45:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:45:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:45:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:45:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:45:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:46:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:47:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:48:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:48:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/02/27 16:48:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Experiment Results:\n",
      "                                             features             model  \\\n",
      "0                                  [hour, day, month]      RandomForest   \n",
      "1                                  [hour, day, month]      RandomForest   \n",
      "2                                  [hour, day, month]      RandomForest   \n",
      "3                            [lag_1d, lag_1w, lag_1m]      RandomForest   \n",
      "4                            [lag_1d, lag_1w, lag_1m]      RandomForest   \n",
      "5                            [lag_1d, lag_1w, lag_1m]      RandomForest   \n",
      "6   [rolling_mean_1d, rolling_mean_7d, rolling_mea...      RandomForest   \n",
      "7   [rolling_mean_1d, rolling_mean_7d, rolling_mea...      RandomForest   \n",
      "8   [rolling_mean_1d, rolling_mean_7d, rolling_mea...      RandomForest   \n",
      "9                                  [hour, day, month]           XGBoost   \n",
      "10                                 [hour, day, month]           XGBoost   \n",
      "11                                 [hour, day, month]           XGBoost   \n",
      "12                           [lag_1d, lag_1w, lag_1m]           XGBoost   \n",
      "13                           [lag_1d, lag_1w, lag_1m]           XGBoost   \n",
      "14                           [lag_1d, lag_1w, lag_1m]           XGBoost   \n",
      "15  [rolling_mean_1d, rolling_mean_7d, rolling_mea...           XGBoost   \n",
      "16  [rolling_mean_1d, rolling_mean_7d, rolling_mea...           XGBoost   \n",
      "17  [rolling_mean_1d, rolling_mean_7d, rolling_mea...           XGBoost   \n",
      "18                                 [hour, day, month]  LinearRegression   \n",
      "19                                 [hour, day, month]  LinearRegression   \n",
      "20                                 [hour, day, month]  LinearRegression   \n",
      "21                           [lag_1d, lag_1w, lag_1m]  LinearRegression   \n",
      "22                           [lag_1d, lag_1w, lag_1m]  LinearRegression   \n",
      "23                           [lag_1d, lag_1w, lag_1m]  LinearRegression   \n",
      "24  [rolling_mean_1d, rolling_mean_7d, rolling_mea...  LinearRegression   \n",
      "25  [rolling_mean_1d, rolling_mean_7d, rolling_mea...  LinearRegression   \n",
      "26  [rolling_mean_1d, rolling_mean_7d, rolling_mea...  LinearRegression   \n",
      "\n",
      "                                      hyperparameters Train/test split  \\\n",
      "0   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.8/0.2   \n",
      "1   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.7/0.3   \n",
      "2   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.9/0.1   \n",
      "3   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.8/0.2   \n",
      "4   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.7/0.3   \n",
      "5   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.9/0.1   \n",
      "6   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.8/0.2   \n",
      "7   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.7/0.3   \n",
      "8   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.9/0.1   \n",
      "9   {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.8/0.2   \n",
      "10  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.7/0.3   \n",
      "11  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.9/0.1   \n",
      "12  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.8/0.2   \n",
      "13  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.7/0.3   \n",
      "14  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.9/0.1   \n",
      "15  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.8/0.2   \n",
      "16  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.7/0.3   \n",
      "17  {'n_estimators': 200, 'max_depth': 7, 'n_jobs'...          0.9/0.1   \n",
      "18                           {'fit_intercept': False}          0.8/0.2   \n",
      "19                           {'fit_intercept': False}          0.7/0.3   \n",
      "20                           {'fit_intercept': False}          0.9/0.1   \n",
      "21                           {'fit_intercept': False}          0.8/0.2   \n",
      "22                           {'fit_intercept': False}          0.7/0.3   \n",
      "23                           {'fit_intercept': False}          0.9/0.1   \n",
      "24                           {'fit_intercept': False}          0.8/0.2   \n",
      "25                           {'fit_intercept': False}          0.7/0.3   \n",
      "26                           {'fit_intercept': False}          0.9/0.1   \n",
      "\n",
      "            Rmse          MAE  \n",
      "0    4115.048829  3252.642416  \n",
      "1    4119.222050  3234.739905  \n",
      "2    4240.277864  3294.678722  \n",
      "3    2805.662295  2097.985374  \n",
      "4    2807.526266  2101.086047  \n",
      "5    2913.779620  2205.139757  \n",
      "6    4540.251421  3606.350660  \n",
      "7    4420.648380  3526.650662  \n",
      "8    4294.748558  3399.582185  \n",
      "9    4045.993102  3160.475268  \n",
      "10   4045.637843  3135.530177  \n",
      "11   4207.326768  3226.367973  \n",
      "12   2934.574734  2177.978815  \n",
      "13   2925.340555  2173.828570  \n",
      "14   3008.677401  2274.374396  \n",
      "15   4962.123711  3856.313192  \n",
      "16   4888.839804  3828.163209  \n",
      "17   4729.365435  3664.125470  \n",
      "18   9968.069049  7947.340374  \n",
      "19  10324.036625  8237.613641  \n",
      "20  10097.856444  7964.009718  \n",
      "21   2806.452001  2078.996705  \n",
      "22   2805.059004  2085.701298  \n",
      "23   2933.004730  2204.126696  \n",
      "24   4511.622209  3607.631745  \n",
      "25   4392.651029  3523.607881  \n",
      "26   4242.316981  3382.535573  \n"
     ]
    }
   ],
   "source": [
    "for model_name, model_class in models.items():\n",
    "    for features in feature_combinations:\n",
    "        X = df[features]\n",
    "        y = df['PJME_MW']\n",
    "        \n",
    "\n",
    "        if model_name == 'RandomForest':\n",
    "            n_estimators_values = hyperparameters['RandomForest']['n_estimators']\n",
    "            max_depth_values = hyperparameters['RandomForest']['max_depth']\n",
    "            \n",
    "            for n_estimators in n_estimators_values:\n",
    "                for max_depth in max_depth_values:\n",
    "                    hyperparameter_set = {'n_estimators': n_estimators, 'max_depth': max_depth, 'n_jobs': -1}\n",
    "                    \n",
    "        elif model_name == 'XGBoost':\n",
    "            n_estimators_values = hyperparameters['XGBoost']['n_estimators']\n",
    "            max_depth_values = hyperparameters['XGBoost']['max_depth']\n",
    "            \n",
    "            for n_estimators in n_estimators_values:\n",
    "                for max_depth in max_depth_values:\n",
    "                    hyperparameter_set = {'n_estimators': n_estimators, 'max_depth': max_depth, 'n_jobs': -1}\n",
    "                    \n",
    "        elif model_name == 'LinearRegression':\n",
    "            fit_intercept_values = hyperparameters['LinearRegression']['fit_intercept']\n",
    "            \n",
    "            for fit_intercept in fit_intercept_values:\n",
    "                hyperparameter_set = {'fit_intercept': fit_intercept}\n",
    "                    \n",
    "\n",
    "        for train_size, test_size in time_splits:\n",
    "\n",
    "            train, test = train_test_split(df, train_size=train_size, shuffle=False)\n",
    "            X_train, y_train = train[features], train['PJME_MW']\n",
    "            X_test, y_test = test[features], test['PJME_MW']\n",
    "\n",
    "\n",
    "            if model_name == 'LinearRegression':\n",
    "                X_train = X_train.dropna()\n",
    "                y_train = y_train.loc[X_train.index]\n",
    "                X_test = X_test.dropna()\n",
    "                y_test = y_test.loc[X_test.index]\n",
    "\n",
    "\n",
    "\n",
    "            with mlflow.start_run():\n",
    "\n",
    "                model = model_class(**hyperparameter_set)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                \n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "    \n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                \n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(y_test[:30], label='Actual') \n",
    "                plt.plot(y_pred[:30], label='Predicted')\n",
    "                plt.title('Actual vs Predicted (1 Month)')\n",
    "                plt.legend()\n",
    "                plt.savefig('actual_vs_predicted_1_month.png')\n",
    "                plt.close()\n",
    "                \n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(y_test[:7], label='Actual')\n",
    "                plt.plot(y_pred[:7], label='Predicted')\n",
    "                plt.title('Actual vs Predicted (1 Week)')\n",
    "                plt.legend()\n",
    "                plt.savefig('actual_vs_predicted_1_week.png')\n",
    "                plt.close()\n",
    "\n",
    "                mlflow.log_param('Model', model_name)\n",
    "                mlflow.log_param('Features', features)\n",
    "                mlflow.log_param('Hyperparameters', hyperparameter_set)\n",
    "                mlflow.log_param('Train/Test Split', f'{train_size}/{test_size}')\n",
    "                mlflow.log_metric('RMSE', rmse)\n",
    "                mlflow.log_metric('MAE', mae)\n",
    "                mlflow.log_artifact('actual_vs_predicted_1_month.png')\n",
    "                mlflow.log_artifact('actual_vs_predicted_1_week.png')\n",
    "\n",
    "\n",
    "                mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "                results.append({\n",
    "                    \"features\": features,\n",
    "                    \"model\": model_name,\n",
    "                    \"hyperparameters\": hyperparameter_set,\n",
    "                    \"Train/test split\": f'{train_size}/{test_size}',\n",
    "                    \"Rmse\": rmse,\n",
    "                    \"MAE\":mae,\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Experiment Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting MLFlow UI...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[Open MLFlow UI](http://localhost:5000)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow UI is running at http://localhost:5000. Press Ctrl+C in the terminal to stop it.\n"
     ]
    }
   ],
   "source": [
    "# Start MLFlow UI from the notebook\n",
    "print(\"\\nStarting MLFlow UI...\")\n",
    "process = subprocess.Popen([\"mlflow\", \"ui\", \"--port\", \"5000\"])  # Starts MLFlow UI on port 5000\n",
    "\n",
    "# Wait a moment to ensure the server starts\n",
    "time.sleep(3)\n",
    "\n",
    "# Display a link to the MLFlow UI\n",
    "display.display(display.Markdown(\"[Open MLFlow UI](http://localhost:5000)\"))\n",
    "\n",
    "print(\"MLFlow UI is running at http://localhost:5000. Press Ctrl+C in the terminal to stop it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start MLFlow experiment\n",
    "# mlflow.set_experiment(\"Energy_consumption_D&T\")\n",
    "\n",
    "# results = []\n",
    "\n",
    "# # Train models with different feature combinations\n",
    "# for features in feature_combinations:\n",
    "#     for model_name, modelClass in models.items():  # Ensure model_name is defined before use\n",
    "#         # Remove lag and roll features only for LinearRegression\n",
    "#         X_selected = df[features] if model_name != \"LinearRegression\" else df[[f for f in features if \"lag\" not in f and \"roll\" not in f]]\n",
    "#         X_selected = X_selected.dropna()  # Remove NaN rows\n",
    "#         y = df.loc[X_selected.index, \"PJME_MW\"]  # Ensure y aligns with filtered X\n",
    "\n",
    "#         model_hyperparameters = hyperparameters[model_name]  # Get hyperparameters\n",
    "\n",
    "#         for param_set in zip(*model_hyperparameters.values()): \n",
    "#             param_dict = dict(zip(model_hyperparameters.keys(), param_set))\n",
    "            \n",
    "#             for train_idx, test_idx in tscv.split(X_selected):  # Fix split to use correct X\n",
    "#                 X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]\n",
    "#                 y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#                 # Initialize the model with appropriate hyperparameters\n",
    "#                 if model_name == \"LinearRegression\":\n",
    "#                     model = modelClass(copy_X=param_dict[\"copy_X\"],\n",
    "#                                        fit_intercept=param_dict[\"fit_intercept\"], \n",
    "#                                        n_jobs=param_dict[\"n_jobs\"], \n",
    "#                                        positive=param_dict[\"positive\"])\n",
    "#                 else:\n",
    "#                     model = modelClass(n_estimators=param_dict[\"n_estimators\"], \n",
    "#                                        max_depth=param_dict[\"max_depth\"])\n",
    "\n",
    "#                 with mlflow.start_run():\n",
    "#                     mlflow.log_param(\"features\", features)\n",
    "#                     mlflow.log_param(\"model_type\", model_name)\n",
    "#                     mlflow.log_param(\"hyperparameters\", param_dict)\n",
    "                    \n",
    "#                     # Train the model\n",
    "#                     model.fit(X_train, y_train)\n",
    "#                     predictions = model.predict(X_test)\n",
    "                    \n",
    "#                     # Calculate metrics\n",
    "#                     rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "#                     mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "#                     # Log metrics\n",
    "#                     mlflow.log_metric(\"RMSE\", rmse)\n",
    "#                     mlflow.log_metric(\"MAE\", mae)\n",
    "\n",
    "#                     # Store results for summary\n",
    "#                     results.append({\n",
    "#                         \"model\": model_name,\n",
    "#                         \"feature_set\": features,\n",
    "#                         \"hyperparameters\": param_dict,\n",
    "#                         \"RMSE\": rmse,\n",
    "#                         \"MAE\": mae\n",
    "#                     })\n",
    "\n",
    "# # Print summary\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(\"\\nSummary of Experiment Results:\")\n",
    "# print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters = {\n",
    "#     \"RandomForest\": [\n",
    "#         {\"n_estimators\": 50, \"max_depth\": 10, \"min_samples_split\": 2},\n",
    "#         {\"n_estimators\": 100, \"max_depth\": 20, \"min_samples_split\": 4},\n",
    "#         {\"n_estimators\": 150, \"max_depth\": None, \"min_samples_split\": 8},\n",
    "#     ],\n",
    "#     \"LogisticRegression\": [\n",
    "#         {\"max_iter\": 100, \"C\": 0.1, \"solver\": \"lbfgs\"},\n",
    "#         {\"max_iter\": 200, \"C\": 1.0, \"solver\": \"liblinear\"},\n",
    "#         {\"max_iter\": 300, \"C\": 10, \"solver\": \"saga\"},\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# # Start MLFlow experiment\n",
    "# mlflow.set_experiment(\"MLFlow Jacob\")\n",
    "\n",
    "# results = []\n",
    "\n",
    "# # Train models with different feature combinations\n",
    "# for features in feature_combinations:\n",
    "#     for model_name, model in zip([\"RandomForest\", \"LogisticRegression\", \"KNN\"], \n",
    "#                                  [RandomForestClassifier(random_state=42), LogisticRegression(max_iter=200)]):\n",
    "#         with mlflow.start_run():\n",
    "#             # Log feature combination and model type\n",
    "#             mlflow.log_param(\"features\", features)\n",
    "#             mlflow.log_param(\"model_type\", model_name)\n",
    "            \n",
    "#             # Train the model\n",
    "#             model.fit(X_train[features], y_train)\n",
    "#             predictions = model.predict(X_test[features])\n",
    "            \n",
    "#             # Calculate metrics\n",
    "#             accuracy = accuracy_score(y_test, predictions)\n",
    "#             precision = precision_score(y_test, predictions, average='weighted')\n",
    "#             recall = recall_score(y_test, predictions, average='weighted')\n",
    "#             f1 = f1_score(y_test, predictions, average='weighted')\n",
    "            \n",
    "#             # Log metrics\n",
    "#             mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#             mlflow.log_metric(\"precision\", precision)\n",
    "#             mlflow.log_metric(\"recall\", recall)\n",
    "#             mlflow.log_metric(\"f1_score\", f1)\n",
    "            \n",
    "#             # Create and log a plot of the metrics\n",
    "#             fig, ax = plt.subplots(figsize=(8, 4))\n",
    "#             metrics = [accuracy, precision, recall, f1]\n",
    "#             metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "#             ax.bar(metric_names, metrics, color='skyblue')\n",
    "#             ax.set_title(f\"{model_name} Metrics for Feature Set: {features}\")\n",
    "#             ax.set_ylim(0, 1)\n",
    "            \n",
    "#             # Save the plot to a temporary file and log it as an artifact\n",
    "#             temp_file = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "#             plt.savefig(temp_file.name)\n",
    "#             mlflow.log_artifact(temp_file.name, artifact_path=\"plots\")\n",
    "#             temp_file.close()\n",
    "            \n",
    "#             # Log the model\n",
    "#             mlflow.sklearn.log_model(model, model_name)\n",
    "            \n",
    "#             # Store results for summary\n",
    "#             results.append({\n",
    "#                 \"features\": features,\n",
    "#                 \"model\": model_name,\n",
    "#                 \"accuracy\": accuracy,\n",
    "#                 \"precision\": precision,\n",
    "#                 \"recall\": recall,\n",
    "#                 \"f1_score\": f1\n",
    "#             })\n",
    "\n",
    "# # Print summary of results\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(\"\\nSummary of Experiment Results:\")\n",
    "# print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
